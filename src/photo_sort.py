import glob
import json
import logging
import os
import re
import shutil
import sys
import tempfile
import zipfile
from datetime import datetime
from pathlib import Path


class PhotoSort:
    """ Sort out google photos, downloaded by takeout.google.com. Copy them to target, split by year.
    Determine year from google photos json files, downloaded with photos.
     """

    def __init__(self, src_arch_dir_param: str = None, trg_dir_param: str = None):
        """
        :param src_arch_dir_param: source folder with downloaded google photos.
        Contains subfolders named takeout-yyyymmddThhmmssZ-zzz. Each folder with files and subfolders in takeout format.
        :param trg_dir_param: target folder to store downloaded photos and prefix with their date.
        """
        # Photos are downloaded to downloads folder by default
        self.src_arch_dir = src_arch_dir_param if src_arch_dir_param else f"{os.getenv('HOME')}/Downloads"

        tmp_dir = Path(tempfile.gettempdir(), self.__class__.__name__)
        self.src_extracted_dir = Path(tmp_dir)
        # Default target dir is in temp folder
        self.trg_dir = trg_dir_param if trg_dir_param else f"{tmp_dir}/Processed"
        logging.info(f"Copy and sort out photos from {self.src_arch_dir} to {self.trg_dir}")

    def process(self):
        """ Extract downloaded takeout-*.zip archives, copy them to target dir, split by year. """
        # self.extract()
        self.copy()

    def extract(self):
        files = glob.glob(os.path.join(self.src_arch_dir, "takeout-*.zip"), recursive=False)
        logging.info(f"Found {len(files)} takeout files in {self.src_arch_dir}")
        for file in files:
            with zipfile.ZipFile(file, "r") as zip_ref:
                logging.info(f"Extract {file} to {self.src_extracted_dir}")
                zip_ref.extractall(self.src_extracted_dir)

    def copy(self):
        """ Read google takeout downloaded photos from src folder.
        Copy them to target folder, in organized manner, change attributes rename. """
        logging.info(f"Copy files from {self.src_extracted_dir} to {self.trg_dir}")
        # Read files info from json description files.
        files_info = self.read_photos_info()

        # Search downloaded google photos, ignore jsons with descriptions
        files = glob.glob(os.path.join(self.src_extracted_dir, "Takeout", "**", "*.*"), recursive=True)
        files = [f for f in files if not f.endswith(".json") and not os.path.isdir(f)]

        all_cnt, copy_cnt, skip_cnt = len(files), 0, 0
        # Copy each of found files to target year's directory
        for src_path in files:

            # Get file info from it's json description
            src_name = os.path.basename(src_path).rstrip(".json")
            src_info = files_info.get(os.path.basename(src_name), None)
            trg_path = self.trg_path(src_path, src_info)

            # Create the target directory if it doesn't exist
            os.makedirs(os.path.dirname(trg_path), exist_ok=True)
            # Copy the file to the target location, replacing it if it already exists
            if not os.path.exists(trg_path):
                shutil.copy2(src_path, trg_path)
                print(f"\rCopied {copy_cnt} of {all_cnt}", end="")
                copy_cnt += 1
            else:
                skip_cnt += 1
        logging.info(f"Total files: {all_cnt}, copied new: {copy_cnt}, skipped old: {skip_cnt}")
        return

    def read_photos_info(self) -> dict[str, dict]:
        """ Read photos info from json files"""
        json_files = glob.glob(os.path.join(self.src_extracted_dir, "Takeout", "**", "*.json"), recursive=True)
        json_dict = dict()
        for json_path in json_files:
            with open(json_path, 'r') as f:
                json_value = json.load(f)
                file_name = os.path.basename(json_path).rstrip(".json")
                json_dict[file_name] = json_value
        return json_dict

    def trg_path(self, src_path, info: dict = None):
        """ Determine target directory for given source file. Directory name is year"""

        name = os.path.basename(src_path)

        if info:
            # If json with info provided
            ts = info["photoTakenTime"]["timestamp"]
            dt = datetime.fromtimestamp(int(ts))
            year = str(dt.year)
        else:
            # Extract year from file name, if no info in json
            dt = self.datetime_of(name)
            year = str(dt.year)

        # If source folder is auto generated by google, target will be year. Otherwise album in target year
        is_autogen_folder = re.compile(r'Photos from \d{4}').findall(src_path)
        if is_autogen_folder:
            trg_dir_name = str(Path(self.trg_dir, year, name))
        else:
            album_name = Path(src_path).parent.name
            trg_dir_name = str(Path(self.trg_dir, year, album_name, name))

        return trg_dir_name

    @staticmethod
    def datetime_of(old_name: str) -> datetime:
        """ Extract datetime from file name like my_photo_2024-02-01-12-23-34 """

        # I found these patterns in google photos files names:
        dt_patterns = [
            # like 20240303_160042
            (re.compile(r'\d{8}_\d{6}'), '%Y%m%d_%H%M%S'),

            # like 2024-03-03-16-02-42
            (re.compile(r'\d{4}-\d{2}-\d{2}-\d{2}-\d{2}-\d{2}'), '%Y-%m-%d-%H-%M-%S'),

            # like 2024-03-03 16.02.42
            (re.compile(r'\d{4}-\d{2}-\d{2} \d{2}\.\d{2}\.\d{2}'), '%Y-%m-%d %H.%M.%S')

        ]

        for pattern, fmt in dt_patterns:
            match = pattern.search(old_name)
            if match:
                return datetime.strptime(match.group(0), fmt)

        # Unknown pattern of file name, datetime not found there
        return datetime.min


if __name__ == "__main__":
    logging.basicConfig(level='INFO')

    src_dir = sys.argv[1] if len(sys.argv) > 1 else None
    trg_dir = sys.argv[2] if len(sys.argv) > 2 else None
    PhotoSort(src_dir, trg_dir).process()
